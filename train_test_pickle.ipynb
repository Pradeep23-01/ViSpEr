{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "import imutils\r\n",
    "import dlib\r\n",
    "import cv2\r\n",
    "\r\n",
    "import imageio\r\n",
    "from imutils import face_utils\r\n",
    "\r\n",
    "import os\r\n",
    "\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "people = ['F01','F02','F04','F05','F06','F07','F08','F09','F10','F11','M01','M02','M04','M07','M08']\r\n",
    "folder_enum = ['01','02','03','04','05','06','07','08', '09', '10']\r\n",
    "instances = ['01','02','03','04','05','06','07','08', '09', '10']\r\n",
    "data_types = ['words']\r\n",
    "words = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']\r\n",
    "\r\n",
    "max_seq_length = 22\r\n",
    "\r\n",
    "X_train = []\r\n",
    "y_train = []\r\n",
    "X_val = []\r\n",
    "y_val = []\r\n",
    "X_test = []\r\n",
    "y_test = []\r\n",
    "\r\n",
    "MAX_WIDTH = 100\r\n",
    "MAX_HEIGHT = 100\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from skimage.transform import resize\r\n",
    "import time\r\n",
    "\r\n",
    "t1 = time.time()\r\n",
    "UNSEEN_VALIDATION_SPLIT = ['09']\r\n",
    "UNSEEN_TEST_SPLIT = ['05']\r\n",
    "directory = \"cropped\"\r\n",
    "\r\n",
    "for person_id in people:\r\n",
    "    tx1 = time.time()\r\n",
    "    for data_type in data_types:\r\n",
    "        for word_index, word in enumerate(folder_enum):\r\n",
    "            for iteration in instances:\r\n",
    "                path = os.path.join(directory, person_id, data_type, word, iteration)\r\n",
    "                filelist = sorted(os.listdir(path + '/'))\r\n",
    "                sequence = [] \r\n",
    "                for img_name in filelist:\r\n",
    "                    if img_name.startswith('color'):\r\n",
    "                        image = imageio.imread(path + '/' + img_name)\r\n",
    "                        image = resize(image, (MAX_WIDTH, MAX_HEIGHT))\r\n",
    "                        image = 255 * image\r\n",
    "                        # Convert to integer data type pixels.\r\n",
    "                        image = image.astype(np.uint8)\r\n",
    "                        sequence.append(image)                        \r\n",
    "                pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]                            \r\n",
    "                sequence.extend(pad_array * (max_seq_length - len(sequence)))\r\n",
    "                sequence = np.array(sequence)\r\n",
    "                                \r\n",
    "                if  iteration in UNSEEN_TEST_SPLIT:\r\n",
    "                    X_test.append(sequence)\r\n",
    "                    y_test.append(word_index)\r\n",
    "                elif iteration in UNSEEN_VALIDATION_SPLIT:\r\n",
    "                    X_val.append(sequence)\r\n",
    "                    y_val.append(word_index)\r\n",
    "                else:\r\n",
    "                    X_train.append(sequence)\r\n",
    "                    y_train.append(word_index)    \r\n",
    "    tx2 = time.time()\r\n",
    "    print(f'Finished reading images for person {person_id}. Time taken : {tx2 - tx1} secs.')    \r\n",
    "    \r\n",
    "t2 = time.time()\r\n",
    "print(f\"Time taken for creating constant size 3D Tensors from those cropped lip regions : {t2 - t1} secs.\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished reading images for person F01. Time taken : 7.718793630599976 secs.\n",
      "Finished reading images for person F02. Time taken : 6.943119049072266 secs.\n",
      "Finished reading images for person F04. Time taken : 9.41447377204895 secs.\n",
      "Finished reading images for person F05. Time taken : 8.225896835327148 secs.\n",
      "Finished reading images for person F06. Time taken : 8.804054975509644 secs.\n",
      "Finished reading images for person F07. Time taken : 11.754110097885132 secs.\n",
      "Finished reading images for person F08. Time taken : 6.600075006484985 secs.\n",
      "Finished reading images for person F09. Time taken : 5.931450605392456 secs.\n",
      "Finished reading images for person F10. Time taken : 5.035379648208618 secs.\n",
      "Finished reading images for person F11. Time taken : 5.054295301437378 secs.\n",
      "Finished reading images for person M01. Time taken : 6.51457405090332 secs.\n",
      "Finished reading images for person M02. Time taken : 7.78283953666687 secs.\n",
      "Finished reading images for person M04. Time taken : 7.251882076263428 secs.\n",
      "Finished reading images for person M07. Time taken : 6.016218185424805 secs.\n",
      "Finished reading images for person M08. Time taken : 8.606441259384155 secs.\n",
      "Time taken for creating constant size 3D Tensors from those cropped lip regions : 111.67676210403442 secs.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X_train = np.array(X_train)\r\n",
    "X_val = np.array(X_val)\r\n",
    "X_test = np.array(X_test)\r\n",
    "\r\n",
    "# X_train = X_train.tolist()\r\n",
    "# X_val = X_val.tolist()\r\n",
    "# X_test = X_test.tolist()\r\n",
    "\r\n",
    "len(X_train)\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(X_val.shape)\r\n",
    "print(X_test.shape)\r\n",
    "\r\n",
    "y_train = np.array(y_train)\r\n",
    "y_val = np.array(y_val)\r\n",
    "y_test = np.array(y_test)\r\n",
    "\r\n",
    "# y_train = y_train.tolist()\r\n",
    "# y_val = y_val.tolist()\r\n",
    "# y_test = y_test.tolist()\r\n",
    "\r\n",
    "print(y_train.shape)\r\n",
    "print(y_val.shape)\r\n",
    "print(y_test.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1200, 22, 100, 100)\n",
      "(150, 22, 100, 100)\n",
      "(150, 22, 100, 100)\n",
      "(1200,)\n",
      "(150,)\n",
      "(150,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1200,)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\r\n",
    "integer_encoded = y_train.reshape(len(y_train), 1)\r\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\r\n",
    "print(onehot_encoded)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "onehot_encoded.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1200, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def normalize_it(X):\r\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True)\r\n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\r\n",
    "    X = (X - v_min)/(v_max - v_min)\r\n",
    "    X = np.nan_to_num(X)\r\n",
    "    return X\r\n",
    "\r\n",
    "from keras.utils import np_utils, generic_utils\r\n",
    "\r\n",
    "X_train = normalize_it(X_train)\r\n",
    "X_val = normalize_it(X_val)\r\n",
    "X_test = normalize_it(X_test)\r\n",
    "\r\n",
    "y_train = y_train.reshape(len(y_train), 1)\r\n",
    "y_train = onehot_encoder.fit_transform(y_train)\r\n",
    "\r\n",
    "y_test = y_test.reshape(len(y_test), 1)\r\n",
    "y_test = onehot_encoder.fit_transform(y_test)\r\n",
    "\r\n",
    "y_val = y_val.reshape(len(y_val), 1)\r\n",
    "y_val = onehot_encoder.fit_transform(y_val)\r\n",
    "\r\n",
    "from sklearn.utils import shuffle\r\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\r\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\r\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)\r\n",
    "\r\n",
    "X_train = np.expand_dims(X_train, axis=4)\r\n",
    "X_val = np.expand_dims(X_val, axis=4)\r\n",
    "X_test = np.expand_dims(X_test, axis=4)\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(X_val.shape)\r\n",
    "print(X_test.shape)\r\n",
    "\r\n",
    "import pickle\r\n",
    "\r\n",
    "with open('pickle_train_test_ohe/X_train.pkl', 'wb') as f:\r\n",
    "  pickle.dump(X_train, f)\r\n",
    "\r\n",
    "with open('pickle_train_test_ohe/y_train.pkl', 'wb') as f:\r\n",
    "  pickle.dump(y_train, f)\r\n",
    "\r\n",
    "with open('pickle_train_test_ohe/X_test.pkl', 'wb') as f:\r\n",
    "  pickle.dump(X_test, f)\r\n",
    "\r\n",
    "with open('pickle_train_test_ohe/y_test.pkl', 'wb') as f:\r\n",
    "  pickle.dump(y_test, f)\r\n",
    "\r\n",
    "with open('pickle_train_test_ohe/X_val.pkl', 'wb') as f:\r\n",
    "  pickle.dump(X_val, f)\r\n",
    "\r\n",
    "with open('pickle_train_test_ohe/y_val.pkl', 'wb') as f:\r\n",
    "  pickle.dump(y_val, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-10-6033e1c24a39>:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = (X - v_min)/(v_max - v_min)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1200, 22, 100, 100, 1)\n",
      "(150, 22, 100, 100, 1)\n",
      "(150, 22, 100, 100, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "USING NP UTILS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\"\"\"def normalize_it(X):\r\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True)\r\n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\r\n",
    "    X = (X - v_min)/(v_max - v_min)\r\n",
    "    X = np.nan_to_num(X)\r\n",
    "    return X\r\n",
    "\r\n",
    "from keras.utils import np_utils, generic_utils\r\n",
    "\r\n",
    "X_train = normalize_it(X_train)\r\n",
    "X_val = normalize_it(X_val)\r\n",
    "X_test = normalize_it(X_test)\r\n",
    "\r\n",
    "y_train = np_utils.to_categorical(y_train, 10)\r\n",
    "y_test = np_utils.to_categorical(y_test, 10)\r\n",
    "y_val = np_utils.to_categorical(y_val, 10)\r\n",
    "\r\n",
    "from sklearn.utils import shuffle\r\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\r\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\r\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)\r\n",
    "\r\n",
    "X_train = np.expand_dims(X_train, axis=4)\r\n",
    "X_val = np.expand_dims(X_val, axis=4)\r\n",
    "X_test = np.expand_dims(X_test, axis=4)\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(X_val.shape)\r\n",
    "print(X_test.shape)\r\n",
    "\r\n",
    "import pickle\r\n",
    "\r\n",
    "with open('pickle_train_test/X_train.pkl', 'wb') as f:\r\n",
    "  pickle.dump(X_train, f)\r\n",
    "\r\n",
    "with open('pickle_train_test/y_train.pkl', 'wb') as f:\r\n",
    "  pickle.dump(y_train, f)\r\n",
    "\r\n",
    "with open('pickle_train_test/X_test.pkl', 'wb') as f:\r\n",
    "  pickle.dump(X_test, f)\r\n",
    "\r\n",
    "with open('pickle_train_test/y_test.pkl', 'wb') as f:\r\n",
    "  pickle.dump(y_test, f)\r\n",
    "\r\n",
    "with open('pickle_train_test/X_val.pkl', 'wb') as f:\r\n",
    "  pickle.dump(X_val, f)\r\n",
    "\r\n",
    "with open('pickle_train_test/y_val.pkl', 'wb') as f:\r\n",
    "  pickle.dump(y_val, f)\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "interpreter": {
   "hash": "b64de0ba76e769a7c3088015f258876bdb4240a199c36c507f14d2fb10bd5d74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}